{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Non-negative Matrix Factorization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ограничения Matrix Factorization\n",
    "\n",
    "Значения в $P$ и $Q$ в MF не поддаются объяснению, т.к. компоненты могут принимать любые значения.\n",
    "\n",
    "### Non-negative Matrix Factorization\n",
    "\n",
    "Описание  [(Lee and Seung, 1999)](http://www.dm.unibo.it/~simoncin/nmfconverge.pdf) позволяют восстановить $P$ и $Q$ в значениях $[0,1]$, которые интерпретируются вероятностью\n",
    "\n",
    "\n",
    "### Функция сходства\n",
    "\n",
    "Эвклидово расстояние используется в NMF и определяется, как\n",
    "\\begin{equation}\n",
    "J = \\frac{1}{2}\\sum_{(u,i) \\in \\kappa}||R_{u,i} - P_uQ_i^{\\top}||^2 + \\lambda_P||P_u||^2 + \\lambda_Q||Q_i||^2\n",
    "\\end{equation}\n",
    "\n",
    "Цель: минимизировать $J$, оптимизируюя параметры $P$ и $Q$ с использованием $\\lambda_P$ и $\\lambda_Q$ параметров регуляризации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from scipy.sparse import csr_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ttsplit(examples, labels, test_size=0.1, verbose=0):\n",
    "    from sklearn.model_selection import train_test_split \n",
    "    \n",
    "    if verbose:\n",
    "        print(\"Train/Test split \")\n",
    "        print(100-test_size*100, \"% of training data\")\n",
    "        print(test_size*100, \"% of testing data\")    \n",
    "\n",
    "    # split data into train and test sets\n",
    "    train_examples, test_examples, train_labels, test_labels = train_test_split(\n",
    "        examples, \n",
    "        labels, \n",
    "        test_size=0.1, \n",
    "        random_state=42, \n",
    "        shuffle=True\n",
    "    )\n",
    "\n",
    "    # transform train and test examples to their corresponding one-hot representations\n",
    "    train_users = train_examples[:, 0]\n",
    "    test_users = test_examples[:, 0]\n",
    "\n",
    "    train_items = train_examples[:, 1]\n",
    "    test_items = test_examples[:, 1]\n",
    "\n",
    "    # Final training and test set\n",
    "    x_train = np.array(list(zip(train_users, train_items)))\n",
    "    x_test = np.array(list(zip(test_users, test_items)))\n",
    "\n",
    "    y_train = train_labels\n",
    "    y_test = test_labels\n",
    "\n",
    "    if verbose:\n",
    "        print()\n",
    "        print('number of training examples : ', x_train.shape)\n",
    "        print('number of training labels : ', y_train.shape)\n",
    "        print('number of test examples : ', x_test.shape)\n",
    "        print('number of test labels : ', y_test.shape)\n",
    "\n",
    "    return (x_train, x_test), (y_train, y_test)\n",
    "\n",
    "\n",
    "def mean_ratings(dataframe):\n",
    "    means = dataframe.groupby(by='userId', as_index=False)['rating'].mean()\n",
    "    return means\n",
    "\n",
    "\n",
    "def normalized_ratings(dataframe, norm_column=\"norm_rating\"):\n",
    "    \"\"\"\n",
    "    Нормализация рейтинга пользователя относительно общего среднего\n",
    "    \"\"\"\n",
    "    mean = mean_ratings(dataframe=dataframe)\n",
    "    norm = pd.merge(dataframe, mean, suffixes=('', '_mean'), on='userId')\n",
    "    norm[f'{norm_column}'] = norm['rating'] - norm['rating_mean']\n",
    "\n",
    "    return norm\n",
    "\n",
    "\n",
    "def rating_matrix(dataframe, column):\n",
    "    crosstab = pd.crosstab(dataframe.userId, dataframe.movieId, dataframe[f'{column}'], aggfunc=sum).fillna(0).values\n",
    "    matrix = csr_matrix(crosstab)\n",
    "    return matrix\n",
    "\n",
    "\n",
    "def scale_ratings(dataframe, scaled_column=\"scaled_rating\"):\n",
    "    dataframe[f\"{scaled_column}\"] = dataframe.rating / 5.0\n",
    "    return dataframe\n",
    "\n",
    "\n",
    "def get_examples(dataframe, labels_column=\"rating\"):\n",
    "    examples = dataframe[['userId', 'movieId']].values\n",
    "    labels = dataframe[f'{labels_column}'].values\n",
    "    return examples, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ids_encoder(ratings):\n",
    "    \"\"\"\n",
    "        Энкодер для более удобной работы\n",
    "    \"\"\"\n",
    "    users = sorted(ratings['userId'].unique())\n",
    "    items = sorted(ratings['movieId'].unique())\n",
    "\n",
    "    # энкодер для пользователей и элементов\n",
    "    uencoder = LabelEncoder()\n",
    "    iencoder = LabelEncoder()\n",
    "\n",
    "    # fit\n",
    "    uencoder.fit(users)\n",
    "    iencoder.fit(items)\n",
    "\n",
    "    # перезапись ID\n",
    "    ratings.userId = uencoder.transform(ratings.userId.tolist())\n",
    "    ratings.movieId = iencoder.transform(ratings.movieId.tolist())\n",
    "\n",
    "    return ratings, uencoder, iencoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ratings = pd.read_csv('ratings.csv')\n",
    "movies = pd.read_csv('movies.csv')\n",
    "\n",
    "m = ratings.userId.nunique()   # всего пользователей\n",
    "n = ratings.movieId.nunique()   # всего элементов\n",
    "\n",
    "ratings, uencoder, iencoder = ids_encoder(ratings)\n",
    "\n",
    "# получение данных в подготовленном виде\n",
    "raw_examples, raw_labels = get_examples(ratings)\n",
    "\n",
    "# train test split\n",
    "(x_train, x_test), (y_train, y_test) = ttsplit(examples=raw_examples, labels=raw_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Non-negative Matrix Factorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NMF:\n",
    "    \n",
    "    def __init__(self, ratings, m, n, uencoder, iencoder, K=10, lambda_P=0.01, lambda_Q=0.01):\n",
    "        \n",
    "        np.random.seed(32)\n",
    "        \n",
    "        # инициализация матриц P / Q по переданной размерности\n",
    "        self.ratings = ratings\n",
    "        self.np_ratings = ratings.to_numpy()\n",
    "        self.K = K\n",
    "        self.P = np.random.rand(m, K)\n",
    "        self.Q = np.random.rand(n, K)\n",
    "        \n",
    "        # гиперпараметры\n",
    "        self.lambda_P = lambda_P\n",
    "        self.lambda_Q = lambda_Q\n",
    "\n",
    "        # энкодеры\n",
    "        self.uencoder = uencoder\n",
    "        self.iencoder = iencoder\n",
    "        \n",
    "        # словарь для сохранения обучения \n",
    "        self.history = {\n",
    "            \"epochs\": [],\n",
    "            \"loss\": [],\n",
    "            \"val_loss\": [],\n",
    "        }\n",
    "    \n",
    "    def print_training_parameters(self):\n",
    "        print('Training NMF ...')\n",
    "        print(f'k={self.K}')\n",
    "        \n",
    "    def mae(self, x_train, y_train):\n",
    "        \"\"\"\n",
    "        функция возвращает MAE\n",
    "        \"\"\"\n",
    "        # кол-во в сэплте\n",
    "        m = x_train.shape[0]\n",
    "        error = 0\n",
    "        for pair, r in zip(x_train, y_train):\n",
    "            u, i = pair\n",
    "            error += abs(r - np.dot(self.P[u], self.Q[i]))\n",
    "        return error / m\n",
    "    \n",
    "    def update_rule(self, u, i, error):\n",
    "        # основные изменения, отличие от MF\n",
    "        I = self.np_ratings[self.np_ratings[:, 0] == u][:, [1, 2]]\n",
    "        U = self.np_ratings[self.np_ratings[:, 1] == i][:, [0, 2]]    \n",
    "        \n",
    "        num = self.P[u] * np.dot(self.Q[I[:, 0]].T, I[:, 1])\n",
    "        dem = np.dot(self.Q[I[:, 0]].T, np.dot(self.P[u], self.Q[I[:, 0]].T)) + self.lambda_P * len(I) * self.P[u]\n",
    "        self.P[u] = num / dem\n",
    "\n",
    "        num = self.Q[i] * np.dot(self.P[U[:, 0]].T, U[:, 1])\n",
    "        dem = np.dot(self.P[U[:, 0]].T, np.dot(self.P[U[:, 0]], self.Q[i].T)) + self.lambda_Q * len(U) * self.Q[i]\n",
    "        self.Q[i] = num / dem\n",
    "    \n",
    "    @staticmethod\n",
    "    def print_training_progress(epoch, epochs, error, val_error, steps=5):\n",
    "        if epoch == 1 or epoch % steps == 0:\n",
    "            print(f\"epoch {epoch}/{epochs} - loss : {round(error, 3)} - val_loss : {round(val_error, 3)}\")\n",
    "                \n",
    "    def fit(self, x_train, y_train, validation_data, epochs=10):\n",
    "\n",
    "        self.print_training_parameters()\n",
    "        x_test, y_test = validation_data\n",
    "        for epoch in range(1, epochs+1):\n",
    "            for pair, r in zip(x_train, y_train):\n",
    "                u, i = pair\n",
    "                r_hat = np.dot(self.P[u], self.Q[i])\n",
    "                e = abs(r - r_hat)\n",
    "                self.update_rule(u, i, e)                \n",
    "            # обучение и тестирование \n",
    "            error = self.mae(x_train, y_train)\n",
    "            val_error = self.mae(x_test, y_test)\n",
    "            self.update_history(epoch, error, val_error)\n",
    "            self.print_training_progress(epoch, epochs, error, val_error, steps=1)\n",
    "        \n",
    "        return self.history\n",
    "    \n",
    "    def update_history(self, epoch, error, val_error):\n",
    "        self.history['epochs'].append(epoch)\n",
    "        self.history['loss'].append(error)\n",
    "        self.history['val_loss'].append(val_error)\n",
    "    \n",
    "    def evaluate(self, x_test, y_test):        \n",
    "        error = self.mae(x_test, y_test)\n",
    "        print(f\"validation error : {round(error,3)}\")\n",
    "        print('MAE : ', error)        \n",
    "        return error\n",
    "      \n",
    "    def predict(self, userid, itemid):\n",
    "        u = self.uencoder.transform([userid])[0]\n",
    "        i = self.iencoder.transform([itemid])[0]\n",
    "        r = np.dot(self.P[u], self.Q[i])\n",
    "        return r\n",
    "\n",
    "    def recommend(self, userid, N=10):\n",
    "        \n",
    "        u = uencoder.transform([userid])[0]\n",
    "        \n",
    "        # предикт\n",
    "        predictions = np.dot(self.P[u], self.Q.T)\n",
    "\n",
    "        # индекст Топ N\n",
    "        # только необходимое кол-во\n",
    "        top_items = self.iencoder.inverse_transform(top_idx)\n",
    "        top_idx = np.flip(np.argsort(predictions))[:N]\n",
    "        preds = predictions[top_idx]\n",
    "\n",
    "        return top_items, preds\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Обучение NMF\n",
    "\n",
    "Параметры :\n",
    "\n",
    "- $k = 10$ кол-во факторов\n",
    "- $\\lambda_P = 0.6$\n",
    "- $\\lambda_Q = 0.6$\n",
    "- epochs = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = ratings['userId'].nunique()  \n",
    "n = ratings['movieId'].nunique() \n",
    "\n",
    "# обучаем\n",
    "nmf = NMF(ratings, m, n, uencoder, iencoder, K=10, lambda_P=0.6, lambda_Q=0.6)\n",
    "history = nmf.fit(x_train, y_train, epochs=10, validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nmf.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NMF with Scikit-suprise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Хватит это терпеть! Пора перестать мучаться, будем использовать готовые решения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating MAE of algorithm NMF on 5 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n",
      "MAE (testset)     0.9625  0.9262  0.9465  0.9299  0.9178  0.9366  0.0160  \n",
      "Fit time          0.35    0.37    0.50    0.55    0.54    0.46    0.08    \n",
      "Test time         0.10    0.19    0.16    0.25    0.16    0.17    0.05    \n"
     ]
    }
   ],
   "source": [
    "from surprise import NMF\n",
    "from surprise import Dataset, Reader\n",
    "from surprise.model_selection import cross_validate\n",
    "\n",
    "# создадим объект \n",
    "reader = Reader(rating_scale=(1, 5))\n",
    "data = Dataset.load_from_df(ratings[['userId', 'movieId', 'rating']], reader)\n",
    "\n",
    "# NMF\n",
    "nmf = NMF(n_factors=10, n_epochs=10)\n",
    "\n",
    "# 5 фолдов для\n",
    "history = cross_validate(nmf, data, measures=['MAE'], cv=5, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Средний результат **mae = 0.93**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
