{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5MzSv49iMF1_"
   },
   "source": [
    "# Matrix Factorization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mGoHyoipMF2B"
   },
   "source": [
    "<b>User-based</b> и <b>Item-based</b> методы фильтрации страдают от <i>data sparsity</i> и <i>scalability</i>, из-за этого мы точно не можем рекомендовать очень хорошо. \n",
    "\n",
    "<b>MF</b> помогает решить это из-за возможности уменьшения размерности матрицы рейтингов."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kSvTMCyVMF2C"
   },
   "source": [
    "Пример: в нашем наборе MovieLens 100k есть $m=610$ пользователей для $n=9724$ элементов. В основном, пользователи коммуницируют менее чем с $1\\%$ элементов, матрица получается очень разреженной. Пример:\n",
    "\n",
    "\\begin{equation}\n",
    "sparsity = 100 - \\frac{\\text{total # ratings}}{m \\times n} = 100 - \\frac{100000}{610\\times 9724} = 98,3\\%\n",
    "\\end{equation}\n",
    "\n",
    "Matrix Factorization (MF) описана здесь <a href='https://ieeexplore.ieee.org/document/5197422'>(Yehuda Koren et al., 2009)</a>. MF декомпозицирут матрицу $R$ в 2 матрицы ( SVD создавало 3):\n",
    "\n",
    "\\begin{equation}\n",
    "R = Q^\\top P\n",
    "\\end{equation}\n",
    "\n",
    "$P \\in \\mathbb{R}^{m\\times k}$ латентные факторы пользователя, а  $Q \\in \\mathbb{R}^{n\\times k}$ латентные факторы элементов. Каждая строка $P$, сообщает $p_u \\in \\mathbb{R}^k$ потребность (вкус в рейтинге) по каждому пользователю $u$ и каждая $q_i \\in \\mathbb{R}^k$ является фичей элемента $i$. Пересечение между $p_u$ и $q_i$ является предсказанным рейтингом для пользователя $u$ по элементу $i$ :\n",
    "\n",
    "\\begin{equation}\n",
    "\\hat{r}_{u,i} = q_{i}^{\\top} p_u.\n",
    "\\end{equation}\n",
    "\n",
    "<img src=\"img/MF.png\">\n",
    "<br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "04D2zA48MF2D"
   },
   "source": [
    "## Matrix Factorization : алгоритм\n",
    "<ol>\n",
    "    <li>Инициализация $P$ и $Q$ с рандомными значениями\n",
    "    <li>Для каждого примера $(u,i)\\in\\kappa$ выставить рейтинг $r_{u,i}$ :\n",
    "        <ul>\n",
    "            <li>вычислить  $\\hat{r}_{u,i} = q_{i}^{\\top} p_u$\n",
    "            <li>вычислить ошибку : $e_{u,i} = |r_{ui} - \\hat{r}_{u,i}|$\n",
    "            <li>обновить $p_u$ и $q_i$:\n",
    "                <ul>\n",
    "                    <li>$p_u \\leftarrow p_u + \\alpha\\cdot (e_{u,i}\\cdot q_i-\\lambda \\cdot p_u)$\n",
    "                    <li>$q_i \\leftarrow q_i + \\alpha\\cdot (e_{u,i}\\cdot p_u-\\lambda \\cdot q_i)$\n",
    "                </ul>\n",
    "        </ul>\n",
    "    <li> повторять до подбора оптимальных параметров\n",
    "</ol>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "x_ohlWURMF2F"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from scipy.sparse import csr_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ttsplit(examples, labels, test_size=0.1, verbose=0):\n",
    "    from sklearn.model_selection import train_test_split \n",
    "    \n",
    "    if verbose:\n",
    "        print(\"Train/Test split \")\n",
    "        print(100-test_size*100, \"% of training data\")\n",
    "        print(test_size*100, \"% of testing data\")    \n",
    "\n",
    "    # split data into train and test sets\n",
    "    train_examples, test_examples, train_labels, test_labels = train_test_split(\n",
    "        examples, \n",
    "        labels, \n",
    "        test_size=0.1, \n",
    "        random_state=42, \n",
    "        shuffle=True\n",
    "    )\n",
    "\n",
    "    # transform train and test examples to their corresponding one-hot representations\n",
    "    train_users = train_examples[:, 0]\n",
    "    test_users = test_examples[:, 0]\n",
    "\n",
    "    train_items = train_examples[:, 1]\n",
    "    test_items = test_examples[:, 1]\n",
    "\n",
    "    # Final training and test set\n",
    "    x_train = np.array(list(zip(train_users, train_items)))\n",
    "    x_test = np.array(list(zip(test_users, test_items)))\n",
    "\n",
    "    y_train = train_labels\n",
    "    y_test = test_labels\n",
    "\n",
    "    if verbose:\n",
    "        print()\n",
    "        print('number of training examples : ', x_train.shape)\n",
    "        print('number of training labels : ', y_train.shape)\n",
    "        print('number of test examples : ', x_test.shape)\n",
    "        print('number of test labels : ', y_test.shape)\n",
    "\n",
    "    return (x_train, x_test), (y_train, y_test)\n",
    "\n",
    "\n",
    "def mean_ratings(dataframe):\n",
    "    means = dataframe.groupby(by='userId', as_index=False)['rating'].mean()\n",
    "    return means\n",
    "\n",
    "\n",
    "def normalized_ratings(dataframe, norm_column=\"norm_rating\"):\n",
    "    \"\"\"\n",
    "    Нормализация рейтинга пользователя относительно общего среднего\n",
    "    \"\"\"\n",
    "    mean = mean_ratings(dataframe=dataframe)\n",
    "    norm = pd.merge(dataframe, mean, suffixes=('', '_mean'), on='userId')\n",
    "    norm[f'{norm_column}'] = norm['rating'] - norm['rating_mean']\n",
    "\n",
    "    return norm\n",
    "\n",
    "\n",
    "def rating_matrix(dataframe, column):\n",
    "    crosstab = pd.crosstab(dataframe.userId, dataframe.movieId, dataframe[f'{column}'], aggfunc=sum).fillna(0).values\n",
    "    matrix = csr_matrix(crosstab)\n",
    "    return matrix\n",
    "\n",
    "\n",
    "def scale_ratings(dataframe, scaled_column=\"scaled_rating\"):\n",
    "    dataframe[f\"{scaled_column}\"] = dataframe.rating / 5.0\n",
    "    return dataframe\n",
    "\n",
    "\n",
    "def get_examples(dataframe, labels_column=\"rating\"):\n",
    "    examples = dataframe[['userId', 'movieId']].values\n",
    "    labels = dataframe[f'{labels_column}'].values\n",
    "    return examples, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ids_encoder(ratings):\n",
    "    \"\"\"\n",
    "        Энкодер для более удобной работы\n",
    "    \"\"\"\n",
    "    users = sorted(ratings['userId'].unique())\n",
    "    items = sorted(ratings['movieId'].unique())\n",
    "\n",
    "    # энкодер для пользователей и элементов\n",
    "    uencoder = LabelEncoder()\n",
    "    iencoder = LabelEncoder()\n",
    "\n",
    "    # fit\n",
    "    uencoder.fit(users)\n",
    "    iencoder.fit(items)\n",
    "\n",
    "    # перезапись ID\n",
    "    ratings.userId = uencoder.transform(ratings.userId.tolist())\n",
    "    ratings.movieId = iencoder.transform(ratings.movieId.tolist())\n",
    "\n",
    "    return ratings, uencoder, iencoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MatrixFactorization:\n",
    "    \n",
    "    def __init__(self, m, n, k=10, alpha=0.001, lamb=0.01):\n",
    "        \"\"\"\n",
    "              \n",
    "        : param\n",
    "            - m : кол-во пользователей\n",
    "            - n : кол-во элементов\n",
    "            - k : длина факторов (для пользователей и элементов)\n",
    "            - alpha : learning rate \n",
    "            - lamb : regularizer\n",
    "        \"\"\"\n",
    "        np.random.seed(32)\n",
    "        \n",
    "        # создаем матрицы P / Q\n",
    "        self.k = k\n",
    "        self.P = np.random.normal(size=(m, k))\n",
    "        self.Q = np.random.normal(size=(n, k))\n",
    "        \n",
    "        # сохраняем гиперпараметры\n",
    "        self.alpha = alpha\n",
    "        self.lamb = lamb\n",
    "        \n",
    "        # словарь для сохранения обучения \n",
    "        self.history = {\n",
    "            \"epochs\":[],\n",
    "            \"loss\":[],\n",
    "            \"val_loss\":[],\n",
    "            \"lr\":[]\n",
    "        }\n",
    "    \n",
    "    def print_training_parameters(self):\n",
    "        print('Обучаем Matrix Factorization  ...')\n",
    "        print(f'k={self.k} \\t alpha={self.alpha} \\t lambda={self.lamb}')\n",
    "    \n",
    "    def update_rule(self, u, i, error):\n",
    "        self.P[u] = self.P[u] + self.alpha * (error * self.Q[i] - self.lamb * self.P[u])\n",
    "        self.Q[i] = self.Q[i] + self.alpha * (error * self.P[u] - self.lamb * self.Q[i])\n",
    "        \n",
    "    def mae(self,  x_train, y_train):\n",
    "        \"\"\"\n",
    "        функция возвращает MAE\n",
    "        \"\"\"\n",
    "        # кол-во в сэплте\n",
    "        M = x_train.shape[0]\n",
    "        error = 0\n",
    "        for pair, r in zip(x_train, y_train):\n",
    "            u, i = pair\n",
    "            error += abs(r - np.dot(self.P[u], self.Q[i]))\n",
    "        return error/M\n",
    "    \n",
    "    def print_training_progress(self, epoch, epochs, error, val_error, steps=5):\n",
    "        if epoch == 1 or epoch % steps == 0 :\n",
    "                print(\"epoch {}/{} - loss : {} - val_loss : {}\".format(epoch, epochs, round(error,3), round(val_error,3)))\n",
    "                \n",
    "    def learning_rate_schedule(self, epoch, target_epochs = 20):\n",
    "        if (epoch >= target_epochs) and (epoch % target_epochs == 0):\n",
    "                factor = epoch // target_epochs\n",
    "                self.alpha = self.alpha * (1 / (factor * 20))\n",
    "                print(\"\\nLearning Rate : {}\\n\".format(self.alpha))\n",
    "    \n",
    "    def fit(self, x_train, y_train, validation_data, epochs=1000):\n",
    "        \"\"\"\n",
    "        Обучение на факторах P и Q с проверкой через тестовый набор данных\n",
    "        \n",
    "        :param\n",
    "            - x_train : пара для обучения (u,i) где рейтинг известный\n",
    "            - y_train : набор рейтингов r_ui для пары (u,i)\n",
    "            - validation_data : tuple (x_test, y_test)\n",
    "            - epochs : кол-во валидаций\n",
    "            \n",
    "        \"\"\"\n",
    "        self.print_training_parameters()\n",
    "        \n",
    "        # валидация\n",
    "        x_test, y_test = validation_data\n",
    "        \n",
    "        # цикл по эпохам\n",
    "        for epoch in range(1, epochs+1):\n",
    "            \n",
    "            # для каждой пары (u,i) и рейтинга r (который известный)\n",
    "            for pair, r in zip(x_train, y_train):\n",
    "\n",
    "                # разкрываем пару значений\n",
    "                u,i = pair\n",
    "\n",
    "                # вычисляем предик\n",
    "                r_hat = np.dot(self.P[u], self.Q[i])\n",
    "\n",
    "                # считаем ошибку\n",
    "                e = abs(r - r_hat)\n",
    "\n",
    "                # обновляем\n",
    "                self.update_rule(u, i, e)\n",
    "  \n",
    "                    \n",
    "                \n",
    "            # финализация\n",
    "            error = self.mae(x_train, y_train)\n",
    "            val_error = self.mae(x_test, y_test)\n",
    "            \n",
    "            # обновление словоря\n",
    "            self.history['epochs'].append(epoch)\n",
    "            self.history['loss'].append(error)\n",
    "            self.history['val_loss'].append(val_error)\n",
    "            \n",
    "            # обновление истории\n",
    "            self.update_history(epoch, error, val_error)\n",
    "            \n",
    "            # print\n",
    "            self.print_training_progress(epoch, epochs, error, val_error, steps=1)\n",
    "        \n",
    "        return self.history\n",
    "    \n",
    "    def update_history(self, epoch, error, val_error):\n",
    "        self.history['epochs'].append(epoch)\n",
    "        self.history['loss'].append(error)\n",
    "        self.history['val_loss'].append(val_error)\n",
    "        self.history['lr'].append(self.alpha)\n",
    "    \n",
    "    def evaluate(self, x_test, y_test):\n",
    "        \"\"\"\n",
    "        Вычисление глобальной ошибки на тестовой выборке     \n",
    "        :param x_test : тестовая пара (u,i) \n",
    "        :param y_test : рейтинг r_ui для всех пар (u,i)\n",
    "        \"\"\"\n",
    "        error = self.mae(x_test, y_test)\n",
    "        print(f\"validation error : {round(error,3)}\")\n",
    "        \n",
    "        return error\n",
    "      \n",
    "    def predict(self, userid, itemid):\n",
    "        \"\"\"\n",
    "        Предикт для всех пользователей и элементов\n",
    "        :param userШd\n",
    "        :param itemId\n",
    "        :return r : предикт\n",
    "        \"\"\"\n",
    "        \n",
    "        u = uencoder.transform([userid])[0]\n",
    "        i = iencoder.transform([itemid])[0]\n",
    "        \n",
    "        # вычисление рейтинга\n",
    "        r = np.dot(self.P[u], self.Q[i])\n",
    "        return r\n",
    "\n",
    "    def recommend(self, userid, N=10):\n",
    "        \"\"\"\n",
    "        Топ N рекомендаций для переданного пользователя\n",
    "\n",
    "        :return(top_items,preds) : Топ N \n",
    "        \"\"\"\n",
    "        \n",
    "        u = uencoder.transform([userid])[0]\n",
    "        \n",
    "        # предикт\n",
    "        predictions = np.dot(self.P[u], self.Q.T)\n",
    "\n",
    "        # индекст Топ N\n",
    "        # только необходимое кол-во\n",
    "        top_items = self.iencoder.inverse_transform(top_idx)\n",
    "        top_idx = np.flip(np.argsort(predictions))[:N]\n",
    "        preds = predictions[top_idx]\n",
    "\n",
    "        return top_items, preds        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Сдетаем тест над данными"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings = pd.read_csv('ratings.csv')\n",
    "movies = pd.read_csv('movies.csv')\n",
    "\n",
    "m = ratings.userId.nunique()   # всего пользователей\n",
    "n = ratings.movieId.nunique()   # всего элементов\n",
    "\n",
    "ratings, uencoder, iencoder = ids_encoder(ratings)\n",
    "\n",
    "# получение данных в подготовленном виде\n",
    "raw_examples, raw_labels = get_examples(ratings)\n",
    "\n",
    "# train test split\n",
    "(x_train, x_test), (y_train, y_test) = ttsplit(examples=raw_examples, labels=raw_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Обучаем Matrix Factorization  ...\n",
      "k=10 \t alpha=0.01 \t lambda=1.5\n",
      "epoch 1/10 - loss : 3.371 - val_loss : 3.441\n",
      "epoch 2/10 - loss : 2.745 - val_loss : 2.812\n",
      "epoch 3/10 - loss : 2.244 - val_loss : 2.313\n",
      "epoch 4/10 - loss : 2.009 - val_loss : 2.078\n",
      "epoch 5/10 - loss : 1.882 - val_loss : 1.95\n",
      "epoch 6/10 - loss : 1.803 - val_loss : 1.871\n",
      "epoch 7/10 - loss : 1.748 - val_loss : 1.816\n",
      "epoch 8/10 - loss : 1.708 - val_loss : 1.777\n",
      "epoch 9/10 - loss : 1.678 - val_loss : 1.747\n",
      "epoch 10/10 - loss : 1.654 - val_loss : 1.723\n"
     ]
    }
   ],
   "source": [
    "# модель\n",
    "MF = MatrixFactorization(m, n, k=10, alpha=0.01, lamb=1.5)\n",
    "\n",
    "# fit \n",
    "history = MF.fit(x_train, y_train, epochs=epochs, validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation error : 1.723\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.723132441351157"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MF.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Нормализованные рейтинги"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings = pd.read_csv('ratings.csv')\n",
    "movies = pd.read_csv('movies.csv')\n",
    "\n",
    "m = ratings.userId.nunique()   # всего пользователей\n",
    "n = ratings.movieId.nunique()   # всего элементов\n",
    "\n",
    "ratings, uencoder, iencoder = ids_encoder(ratings)\n",
    "\n",
    "# нормализация по среднему\n",
    "normalized_column_name = \"norm_rating\"\n",
    "ratings = normalized_ratings(ratings, norm_column=normalized_column_name)\n",
    "\n",
    "# подготовленные данные с нормализацией\n",
    "raw_examples, raw_labels = get_examples(ratings, labels_column=normalized_column_name)\n",
    "\n",
    "# train test split\n",
    "(x_train, x_test), (y_train, y_test) = ttsplit(examples=raw_examples, labels=raw_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Обучаем Matrix Factorization  ...\n",
      "k=10 \t alpha=0.01 \t lambda=1.5\n",
      "epoch 1/10 - loss : 0.801 - val_loss : 0.79\n",
      "epoch 2/10 - loss : 0.76 - val_loss : 0.753\n",
      "epoch 3/10 - loss : 0.752 - val_loss : 0.747\n",
      "epoch 4/10 - loss : 0.749 - val_loss : 0.745\n",
      "epoch 5/10 - loss : 0.748 - val_loss : 0.744\n",
      "epoch 6/10 - loss : 0.747 - val_loss : 0.744\n",
      "epoch 7/10 - loss : 0.747 - val_loss : 0.744\n",
      "epoch 8/10 - loss : 0.746 - val_loss : 0.743\n",
      "epoch 9/10 - loss : 0.746 - val_loss : 0.743\n",
      "epoch 10/10 - loss : 0.746 - val_loss : 0.743\n"
     ]
    }
   ],
   "source": [
    "# модель\n",
    "MF = MatrixFactorization(m, n, k=10, alpha=0.01, lamb=1.5)\n",
    "\n",
    "# fit \n",
    "history = MF.fit(x_train, y_train, epochs=epochs, validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation error : 0.743\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7432042455456079"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MF.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Предикт"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_hzclXP0RL8V"
   },
   "source": [
    "Латентные факторы в матрицах $P$ и $Q$ позволяют создавать предикт рейтингов для элементов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>rating_mean</th>\n",
       "      <th>norm_rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1260759144</td>\n",
       "      <td>2.55</td>\n",
       "      <td>-0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>833</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1260759179</td>\n",
       "      <td>2.55</td>\n",
       "      <td>0.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>859</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1260759182</td>\n",
       "      <td>2.55</td>\n",
       "      <td>0.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>906</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1260759185</td>\n",
       "      <td>2.55</td>\n",
       "      <td>-0.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>931</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1260759205</td>\n",
       "      <td>2.55</td>\n",
       "      <td>1.45</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userId  movieId  rating   timestamp  rating_mean  norm_rating\n",
       "0       0       30     2.5  1260759144         2.55        -0.05\n",
       "1       0      833     3.0  1260759179         2.55         0.45\n",
       "2       0      859     3.0  1260759182         2.55         0.45\n",
       "3       0      906     2.0  1260759185         2.55        -0.55\n",
       "4       0      931     4.0  1260759205         2.55         1.45"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings.userid = uencoder.inverse_transform(ratings.userId.to_list())\n",
    "ratings.itemid = iencoder.inverse_transform(ratings.movieId.to_list())\n",
    "ratings.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "WjQN_N1WRKSm",
    "outputId": "0003d90b-3c19-4af8-c77f-5206a60d5be5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.188451632987444"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "4.188679 + MF.predict(userid=1, itemid=1) # добавим средний рейтинг для предикта, т.к. ранее мы нормализовали"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.00022736701255557363"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MF.predict(userid=1, itemid=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "5.MatrixFactorization.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
